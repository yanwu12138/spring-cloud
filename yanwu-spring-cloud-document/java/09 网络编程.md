## [OSI七层模型](https://blog.csdn.net/ThinkWon/article/details/104903925)
- 应用层：为应用服务提供服务
- 表示层：数据格式转化、数据加密
- 会话层：管理、维护会话
- 传输层：管理、维护端到端的连接
- 网络层：IP地址及路由选择
- 数据链路层：提供介质访问和链路管理
- 物理层：物理硬件等

![clipboard](https://typroa12138.oss-cn-hangzhou.aliyuncs.com/image/20200628140059.png)

***
## TCP & UDP
### [TCP](https://blog.csdn.net/qzcsu/article/details/72861891?depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.nonecase)
TCP是一种面向连接的、可靠的、基于字节流的传输层通信协议，在发送数据前，通信双方必须在彼此间建立一条连接。所谓的“连接”，其实是客户端和服务端保存的一份关于对方的信息，如ip地址、端口号等。

TCP可以看成是一种字节流，它会处理IP层或以下的层的丢包、重复以及错误问题。在连接的建立过程中，双方需要交换一些连接的参数。这些参数可以放在TCP头部。

一个TCP连接由一个4元组构成，分别是两个IP地址和两个端口号。一个TCP连接通常分为三个阶段：连接、数据传输、退出（关闭）。通过三次握手建立一个链接，通过四次挥手来关闭一个连接。

当一个连接被建立或被终止时，交换的报文段只包含TCP头部，而没有数据。

#### TCP报头结构
![clipboard](https://typroa12138.oss-cn-hangzhou.aliyuncs.com/image/20200628140119.png)

#### 三次握手
1. 客户端发送初始序号`seq=x`和`syn=1`请求标志
2. 服务器发送请求标志`syn=1`，发送确认标识`ACK=1`，发送自己的序列号`seq=y`，发送客户端的确认序列号`ack=x+1`
3. 客户端发送ACK确认好，发送自己的序号`seq=x+1`，发送对方确认号`sck=y+1`

![20200628140140](https://typroa12138.oss-cn-hangzhou.aliyuncs.com/image/20200628140140.gif)

#### 四次挥手
1. 客户端发出释放`FIN=1`，自己序列号`seq=u`，进入 ___FIN-WAIT-1___ 状态
2. 服务器收到客户端的后，发出`ACK=1`确认标志和客户端的确认号`ack=u+1`，自己的序列号`seq=v`，进入 ___CLOSE-WAIT___ 状态
3. 客户端收到服务器确认结果后，进入 ___FIN-WAIT-2 ___ 状态。此时服务器发送释放`FIN=1`信号，确认标志`ACK=1`，确认序号`ack=u+1`，自己序号`seq=w`，服务器进入 ___LAST-ACK___（最后确认态）
4. 客户端收到回复后，发送确认`ACK=1`，`ack=w+1`，自己的`seq=u+1`，客户端进入 ___TIME-WAIT___ （时间等待）。
    1. 客户端经过2个最长报文段寿命后，客户端CLOSE；
    2. 服务器收到确认后，立刻进入CLOSE状态。

![20200628140219](https://typroa12138.oss-cn-hangzhou.aliyuncs.com/image/20200628140219.gif)
#### TCP & UDP
| 协议 | 建立连接 |  安全  |   丢包   | 数据包大小 |
| :--: | :------: | :----: | :------: | :--------: |
| TCP  |   需要   |  安全  |  不丢包  |            |
| UDP  |  不需要  | 不安全 | 容易丢包 |  64k以内   |

##### 相关问题
###### 为什么TCP连接的时候是3次？2次不可以吗？
因为需要考虑连接时丢包的问题，如果只握手2次，第二次握手时如果服务端发给客户端的确认报文段丢失，此时服务端已经准备好了收发数据(可以理解服务端已经连接成功)，而客户端一直没收到服务端的确认报文，所以客户端就不知道服务端是否已经准备好了(可以理解为客户端未连接成功)，这种情况下客户端不会给服务端发数据，也会忽略服务端发过来的数据。

如果是三次握手，即便发生丢包也不会有问题，比如如果第三次握手客户端发的确认ack报文丢失，服务端在一段时间内没有收到确认ack报文的话就会重新进行第二次握手，也就是服务端会重发SYN报文段，客户端收到重发的报文段后会再次给服务端发送确认ack报文。

###### 为什么TCP连接的时候是3次，关闭的时候却是4次？
因为只有在客户端和服务端都没有数据要发送的时候才能断开TCP。而客户端发出FIN报文时只能保证客户端没有数据发了，服务端还有没有数据发客户端是不知道的。而服务端收到客户端的FIN报文后只能先回复客户端一个确认报文来告诉客户端我服务端已经收到你的FIN报文了，但我服务端还有一些数据没发完，等这些数据发完了服务端才能给客户端发FIN报文(所以不能一次性将确认报文和FIN报文发给客户端，就是这里多出来了一次)。

###### 为什么客户端发出第四次挥手的确认报文后要等2MSL的时间才能释放TCP连接
这里同样是要考虑丢包的问题，如果第四次挥手的报文丢失，服务端没收到确认ack报文就会重发第三次挥手的报文，这样报文一去一回最长时间就是2MSL，所以需要等这么长时间来确认服务端确实已经收到了。

###### 如果已经建立了连接，但是客户端突然出现故障了怎么办？
TCP设有一个保活计时器，客户端如果出现故障，服务器不能一直等下去，白白浪费资源。服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75秒钟发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。

### ServerSocket
#### socket：是一个四元组
四元组：ClientIP:ClientPort对应ServerIP:ServerPort

通过窗口机制解决拥塞

***
## IO
### 文件系统IO
kernel：内核
VFS：虚拟文件系统
FD：文件描述符：打开的文件所持有的
inode：在虚拟文件系统当中，每个文件在打开的时候都会有一个inode号
pagecache：页缓存，内存中对数据的缓存，默认4k大小，两个程序读取同一个文件时
dirty：脏

如果程序读取了磁盘中的文件，那么这些文件会缓存到pagecache中，当程序修改了某一个pagecache中的数据时，那么该pagecache会被标记为dirty的，最终通过flush写到磁盘中去。脏页写入磁盘的方式有两种：
- 程序等待内核自动刷新
- 程序调用内核刷新

bytebuffer：想写的时候compact，想读的时候flip

### 内存和IO关系

### 网络IO

#### BIO模型
同步阻塞IO，它的阻塞是在accept函数和recv函数这两个地方，BIO的服务端执行顺序为：
- 服务端启动后，会创建一个socket，并且随机返回一个文件描述符（fd-A）
- 然后将这个文件描述符（fd-A）和server的端口bind
- bind后内核会进入listen状态监听这个文件描述符（通过 __netstat -natp__ 命令可以查看到该LISTEN状态）
- 监听建立完后服务会进行系统调用，通过accept函数等待客户端链接，此时进入 __阻塞状态__，等待客户端链接
- 当有新的客户端建立链接进来后，会给对应的客户端分配一个新的文件描述符（fd-B）
- 分配完文件描述符（fd-B）后服务端会clone一个线程来通过recv函数来读取该文件描述符的内容，此时clone出来的线程也会进入 __阻塞状态__

![clipboard](https://typroa12138.oss-cn-hangzhou.aliyuncs.com/image/20200628140248.png)

##### 弊端
- 阻塞（booking）

#### NIO模型
同步非阻塞IO，NIO的诞生主要是为了解决BIO的阻塞问题。使用BIO模型时，当有新的连接进来时，会clone出新的线程出来读取对应的socket中的信息，所以当连接数很大的时候，会有很多的系统资源浪费在：线程调度、用户态内核态切换、内存空间等等的资源消耗上，服务端和客户端通过configureBlocking(falg)设置为是否阻塞【true：阻塞；false：不阻塞】，NIO的服务端执行顺序为：
- 服务端启动后，会创建一个socket，并且随机返回一个文件描述符（fd-A）
- 然后将这个文件描述符（fd-A）和server的端口bind
- bind后内核会进入listen状态监听这个文件描述符（通过 __netstat -natp__ 命令可以查看到该LISTEN状态）
- 由于通过configureBlocking(false)将服务端设置为非阻塞，所以此时通过服务进行系统调用通过accept函数等待客户端链接时，__不会被阻塞__，而是会根据场景直接返回，不停的循环检查accept函数的返回值判断是否有新的客户端进来：
    - 有客户端连接进来：给对应的客户端分配一个新的文件描述苻（fd-B），并且通过configureBlocking(false)将对应的客户端也设置为 __非阻塞__
    - 没有客户端连接进来：OS：返回 -1；JDK：返回null
- 循环通过recv函数依次读取所有客户端判断是否有发送数据过来，进行相应的业务处理

##### channel
一个channel代表一个文件

##### buffer
channel读写文件的单位

![clipboard](https://typroa12138.oss-cn-hangzhou.aliyuncs.com/image/20200628140308.png)

position <= limit <= capacity
###### capacity
buffer的容量
###### limit
buffer可供读写的临界点
###### position
当前读写的位置

##### mmap

##### selector
NIO的核心，将channel注册到selector

###### 函数
- 通过register()函数将channel注册到selector
- 通过keys()函数返回所有注册上来的channel的key的集合
- 通过selectionKey()函数返回准备好可操作的channel的key的集合，selectionKey集合中的channel的key使用完后必须使用Iterator.remove()函数进行销毁，不然会导致重复消费

![clipboard](https://typroa12138.oss-cn-hangzhou.aliyuncs.com/image/20200628140338.png)

##### 弊端
- 当并发非常大的时候，比如一次循环到accept有10个客户端同时发送连接请求过来，那么有可能只有第一个连接建立成功，其他的连接请求会被丢掉
- 如果有10K个连接的时候，每循环recv一次的时间复杂度是O(10000)，此时很多调用是无意义的

#### 多路复用器模型
所谓的多路复用的意思是指：通过一次系统调用获取所有的IO的状态

多路复用器只负责返回对应的IO连接的状态，然后由程序去对有状态的那些IO去读写

其实 __NIO和select、pool都是要遍历所有IO的询问状态__，但不同点在于：NIO是由 __服务去循环，这种方式会频繁的产生用户态到内核态的切换__；而select与poll的 __系统调用是一次用户态到内核态切换，过程中将所有的文件描述符传递给内核，内核根据这些文件描述符遍历__，修改状态

##### select
将服务所有连接所持有的文件描述符作为参数通过服务调用内核的select函数，然后select函数会返回对应有文件读写事件的发生的文件描述符，服务再去处理相对应的文件描述符的读写

###### 弊端
最多能够接受1024个文件描述符

##### poll
与select相似，区别是poll没有1024的限制

###### select & poll的弊端
- 每次调用都要重复传递所有文件描述符
- 在内核态中需要遍历所有的文件描述符

###### IO中断级别
- package
- buffer
- 轮询

###### 回调（callback）
- 根据中断向量表中间的中断号和回调执行对应的回调函数

##### epoll
在epoll之前的callback，只是完成了将网卡发来的数据走内核网络协议栈最终关联到文件描述符的buffer，所以在某一个时间如果从应用程序询问内核某一个或者某些文件描述符是否有读写事件时，会有状态返回

##### select、poll && epoll
在Java中，select、poll、epoll都是通过Selector类来实现

![clipboard](https://typroa12138.oss-cn-hangzhou.aliyuncs.com/image/20200628140402.png)

##### 零拷贝

## [Netty](https://www.sohu.com/a/272879207_463994)
### 事件循环组
通过 __线程的环形队列__ 实现事件循环组，通过事件循环组实现异步操作
### 执行器
特殊的事件循环组

自己管理内存，减少上下文切换

- netty-buffer
- netty-codec